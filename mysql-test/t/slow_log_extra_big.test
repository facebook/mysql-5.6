#
# Test --log-slow-extra
#

-- source include/have_innodb.inc

--let $file_format_save = `SELECT @@innodb_file_format`
set @my_slow_logname = @@global.slow_query_log_file;

#
# Delete the log file here because if the test is run with the
# --repeat option, the result is concatenated to the log file,
# and the test fails.
#
--exec rm -f $MYSQLTEST_VARDIR/mysqld.1/data/slow_log_extra_big-slow.log

set global slow_query_log_file = "slow_log_extra_big-slow.log";
--let $innodb_lru_io_to_unzip_factor_save = `SELECT @@innodb_lru_io_to_unzip_factor`
set global innodb_lru_io_to_unzip_factor=50;

#
# Confirm that per-query stats work.
#
set session long_query_time = 20;
--disable_warnings
--disable_query_log
drop table if exists big_table_slow;
create table big_table_slow (id int primary key auto_increment, v varchar(200), t text) engine=innodb key_block_size=8;

insert into big_table_slow values (null, lpad("v", 190, "b"), lpad("a", 3000, "b"));
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;
insert into big_table_slow select null, v, t from big_table_slow;

--enable_query_log
--enable_warnings

set global long_query_time = 0;

connect (con,localhost,root,,);

--echo # Confirm that Read_time is correct in the slow query log

select count(*) from big_table_slow;

connect (con1,localhost,root,,);
select count(*) from big_table_slow;

select count(*) from big_table_slow where id>1000 and id<2000;

select * from big_table_slow where id=2;

select count(*) from big_table_slow where id >10000;

select count(*) from big_table_slow where id < 100000;

--echo # Confirm that the unzip_LRU to LRU ratio is about 10%

select VARIABLE_VALUE into @dlen from information_schema.global_status
where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_DATA';

select VARIABLE_VALUE into @ulen from information_schema.global_status
where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_UNZIP_LRU';

--disable_query_log
select (@ulen / @dlen) >= 0.05 as large_enough, (@ulen / @dlen) <= 0.30 as small_enough;
--enable_query_log

--echo # Confirm that the unzip_LRU to LRU ratio is about 20%

set global innodb_unzip_lru_pct = 20;

select count(*) from big_table_slow;

select VARIABLE_VALUE into @dlen from information_schema.global_status
where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_DATA';

select VARIABLE_VALUE into @ulen from information_schema.global_status
where VARIABLE_NAME = 'INNODB_BUFFER_POOL_PAGES_UNZIP_LRU';

--disable_query_log
select (@ulen / @dlen) >= 0.15 as large_enough, (@ulen / @dlen) <= 0.40 as small_enough;
--enable_query_log

--echo # Cleanup

connection default;
set global long_query_time=1;
disconnect con1;
disconnect con;
let $count_sessions= 1;
--source include/wait_until_count_sessions.inc
drop table big_table_slow;

eval SET GLOBAL innodb_file_format = \"$file_format_save\";
set global slow_query_log_file = @my_slow_logname;
eval SET GLOBAL innodb_lru_io_to_unzip_factor = $innodb_lru_io_to_unzip_factor_save;
set global innodb_unzip_lru_pct = 10;

--echo #
--echo # This is a hack to check the log result.
--echo # We strip off time related fields (non-deterministic) and verify the rest are correct.
--echo #

--perl
open FILE, "$ENV{'MYSQLTEST_VARDIR'}/mysqld.1/data/slow_log_extra_big-slow.log" or die;
my @lines = <FILE>;
foreach $line (@lines) {
  if ($line =~ m/^# Query_time/) {
    $line =~ m/(Rows_sent.*) Thread_id.* (Errno.*) Start.*/;
    print "$1 $2\n";
  }
}
EOF

--exit
