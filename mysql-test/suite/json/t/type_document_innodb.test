--source include/have_innodb.inc
--source include/master-slave.inc
connection master;

# Add suppression for expected warning(s) in error log
call mtr.add_suppression("Resizing redo log from");
call mtr.add_suppression("Starting to delete and rewrite log files");
call mtr.add_suppression("New log files created");

--disable_warnings
drop table if exists t, t1, t2, t3, t_big, t_big2;
--enable_warnings

SET @start_allow_document_type = @@global.allow_document_type;
SELECT @start_allow_document_type;

# Fail to create a document column with "not null"
--error ER_DOCUMENT_FIELD_NOT_NULL
create table t (i int(8), a document not null, s text(255)) engine=innodb;

# Fail to create table with document column with non-innodb engine
--error ER_DOCUMENT_FIELD_IN_NON_INNODB_TABLE
create table t (i int(8), a document, s text(255)) engine=myisam;

# Fail to create table with document column with size specification
--error 1064
create table t (i int(8), a document(65535), s text(255)) engine=innodb;

# Fail to create table with document column with primary key on it
--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create table t (i int(8), a document, s text(255), primary key(a)) engine=innodb;

# Fail to create table with partitioning on a document column
--error ER_FIELD_TYPE_NOT_ALLOWED_AS_PARTITION_FIELD
create table t (i int(8), a document, s text(255))
  partition by range columns(a)
  (partition p0 values less than (0) engine=innodb);

# Fail to create table with partitioning on a non-document column but with non-innodb engine
--error ER_DOCUMENT_FIELD_IN_NON_INNODB_TABLE
create table t (i int(8), a document, s text(255))
  partition by range columns(i)
  (partition p0 values less than (0) engine=myisam);

# Testing name resolution on non-document column
# https://github.com/facebook/mysql-5.6/issues/139
CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY AUTO_INCREMENT, b INT) engine=innodb;
--error ER_ILLEGAL_REFERENCE
SELECT 1 FROM t1 AS t1_outer GROUP BY a HAVING (SELECT t1_outer.b FROM t1  AS t1_inner LIMIT 1);
drop table t1;
# Similar to the above test case, if the column is a document column,
# we will try to resolve the identifiers as document path.
CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY AUTO_INCREMENT, b document) engine=innodb;
--error ER_BAD_FIELD_ERROR
SELECT 1 FROM t1 AS t1_outer GROUP BY a HAVING (SELECT t1_outer.b FROM t1  AS t1_inner LIMIT 1);
drop table t1;

# Create table with a document column that can be NULL
create table t (i int(8), a document, s text(255), primary key (i)) engine=innodb;
show create table t;

# Fail to alter a document column to "not null"
--error ER_DOCUMENT_FIELD_NOT_NULL
alter table t change a a document not null;

# Fail to create index on a document column
--error ER_DOCUMENT_KEY_NOT_SUPPORTED
alter table t add primary key (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
alter table t add index (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create index doc_idx on t (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create index doc_idx on t (i, a);

# Fail to partition table on document column
--error ER_DOCUMENT_FIELD_IN_PART_FUNC_ERROR
alter table t partition by hash(a) partitions 8;

# Insert invalid JSON, insertion will fail, expecting errors
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t values (1, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", }', 'a1');

# Insert invalid values, insertion will succeed, the document filed will be NULL, expecting warnings
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t values (2, ' ', 'a2');
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t values (3, 123, 'a3');
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t values (4, 123.456, 'a4');

# explicit NULL is ok
insert into t values (1, NULL, 'a1');
insert into t values (2, NULL, 'a2');
insert into t values (3, NULL, 'a3');
insert into t values (4, NULL, 'a4');

# Update with invalid values, it will fail, expecting errors 
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
update t set a='{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", }' where i = 1;
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
update t set a=111222333444555666777888999 where i = 2;
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
update t set a=123456789.123456789;

# Default is NULL
update t set a=DEFAULT;

# Insert JSON document in plain text
insert into t values (5, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", "zipcode":98761 } }', 'a5');
insert into t values (6, '{ "id":102, "name":"Bob", "phone":6507770002, "address":{ "houseNumber":1002, "streetName":"2nd", "zipcode":98762 } }', 'a6');
insert into t values (7, '{ "id":103, "name":"Charlie", "phone":6507770003, "address":{ "houseNumber":1003, "streetName":"3rd", "zipcode":98763, "hoa":39.99 } }', 'a7');
insert into t values (8, '{ "id":104, "name":"David", "phone":6507770004, "address":{ "houseNumber":1004, "streetName":"4th", "zipcode":98764 }, "children":["Alex", "Bob", "Charlie"] }', 'a8');

# Load data from a file
load data infile '../../std_data/type_document_innodb.txt' into table t;

# Load data from a file containing invalid document, load will fail
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
load data infile '../../std_data/type_document_innodb_invalid.txt' into table t;

select * from t;
select a from t;

# Temp table with a document type column
# In MySQL 5.6 all temp tables are created by MyISAM engine. But temp tables with document
# type columns still will be handled correctly since they will be treated as blobs.

# Create a table and populate it with some data
create table t1 (a int auto_increment, b varchar(64), c text, d document, primary key (a), key (b, c(128))) engine=innodb;

# Here we end up with 16382 rows in the table
--disable_query_log
insert into t1 (b, c, d) values (repeat('b', 64), repeat('c', 256), '{ "id":201, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "street":"1st", "zipcode":98761 } }');
insert into t1 (b, c, d) values (repeat('B', 64), repeat('C', 256), '{ "id":202, "name":"David", "phone":6507770002, "address":{ "houseNumber":1004, "street":"2nd", "zipcode":98762 }, "children":["Alex", "Bob", "Charlie"] }');
let $i=12;
while ($i) {
  --eval INSERT INTO t1 (b, c, d) VALUES ($i, $i * $i, '{ "id":202, "name":"David", "phone":6507770002, "address":{ "houseNumber":1004, "street":"2nd", "zipcode":98762 }, "children":["Alex", "Bob", "Charlie"] }');
  INSERT INTO t1 (b, c, d) SELECT b, c, d FROM t1 order by a;
  dec $i;
}
--enable_query_log

SELECT * FROM t1 WHERE a >= 1000 and a <= 1010;

--error 1064
SELECT CAST(c as document) FROM t1 WHERE a >= 1000 and a <= 1010;

# Test document's nesting levels
create table t2 (i int(8) auto_increment, a document, primary key (i)) engine=innodb;

# invalid JSON with empty value (nesting level is OK)
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('{"a":',100));
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('["a",',100));

# invalid JSON with too many nesting levels
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('{"a":',101));
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('{"a":',10000));
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('["a",',101));
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2(a) values (repeat('["a",',10000));

# regression tests for https://reviews.facebook.net/D56187
insert into t2(a) values (concat('{"k1":[', repeat('{},', 200), '{}]}'));
insert into t2(a) values (concat('{"k2":[', repeat('[],', 200), '[]]}'));
insert into t2(a) values (concat('{"k3":[', repeat('{},', 100), repeat('[],', 100), '[]]}'));
insert into t2(a) values (concat('[', repeat('[],', 200), '[]]'));
select * from t2;

drop table t2;

# Create table with a document column that can be NULL
create table t_big (i int(8), a document, s text(255), primary key (i)) engine=innodb;
show create table t_big;

# Insert a document whose FBSON size is a little bit less than 16MB (the max size of document type)
# This insertion will succeed
insert into t_big values (1, concat("{", repeat("\"json-key\":\"json-value\",", 670000), "\"last\":100}"), 'aaa');

# Insert a document whose FBSON size is a little bit greater than 16MB (the max size of document type)
# This insertion will succeed but with warnings, the document column will be NULL
--error ER_TOO_BIG_DOCUMENT_FIELDLENGTH
insert into t_big values (2, concat("{", repeat("\"json-key\":\"json-value\",", 700000), "\"last\":100}"), 'bbb');

select count(*) from t_big;
select i, s from t_big;

# Disable document type when @@global.allow_document_type is false.
SET @@global.allow_document_type = false;
SELECT @@global.allow_document_type;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
create table t2 (i int(8), a document, s text(255)) engine=innodb;

create table t2 (i int(8), s text(255)) engine=innodb;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
alter table t2 add column a document;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
alter table t2 modify column s document;

# Enable document type
SET @@global.allow_document_type = true;
SELECT @@global.allow_document_type;

alter table t2 add column a document;

alter table t2 modify column s document;

# Restore the original value
SET @@global.allow_document_type = @start_allow_document_type;
SELECT @@global.allow_document_type;

checksum table t_big;
sync_slave_with_master;
# Should be same as that on master
checksum table t_big;

connection master;
drop table t, t1, t2, t_big;

--disable_warnings
drop table if exists t4, t5;
--enable_warnings
create table t4 (i int(8), a document, s text(255)) engine = innodb;
# Test FBSon with escape
insert into t4 values(1, "{\"Name\":\"Json\\tXia\"}", "escape in value");
insert into t4 values(2, "{\"Mobile\\tPhone\":123456}", "escape in key");
insert into t4 values(3, "{\"\\b\\f\\n\\r\\t\":\"123\\t\\r\\n\\f\\bABC\"}", "escape chars");
insert into t4 values(4, "{\"Status\":\"\\u675f\\u5e26\\u7ed3\\u53d1\\u523b\\u5f55\\u673a\\u5076\\u5c14\\u4e94\\u798f\\u805a\\u54e6\"}", "escape of Unicode");
insert into t4 values(5, "{\"\\u0009\":\"\\u000d\\u000a\"}", "escape of Unicode for control char");
insert into t4 values(6, "{\"Control\":\"\\u0002\"}", "escape of Unicode for control char");
insert into t4 values(7, "{\"NULL\":\"\\u0000\"}", "Unicode for NULL");
insert into t4 values(8, '{"NULL":"\\u0000"}', "Unicode for NULL");
select * from t4;

# Test FBSon with wrong escape
create table t5 (i int(8), a document, s text(255)) engine = innodb;
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t5 values(1, "{\"BAD\":\"123\\u0xDFFE\"}", "Bad Unicode");
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t5 values(2, "{\"BAD\":\"\\u0x0000\"}", "Bad Unicode");
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t5 values(3, "{\"BAD\":\"\\u0x0000010\"}", "Bad Unicode");
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t5 values(4, "{\"BAD\":\"\\u0xD801\"}", "Bad UTF16");
select * from t5;

drop table t4, t5;
--source include/rpl_end.inc
