--source include/have_innodb.inc
--source include/master-slave.inc
connection master;

# Add suppression for expected warning(s) in error log
call mtr.add_suppression("Resizing redo log from");
call mtr.add_suppression("Starting to delete and rewrite log files");
call mtr.add_suppression("New log files created");

--disable_warnings
drop table if exists t, t1, t2, t3, t_big, t_big2;
--enable_warnings

SET @start_allow_document_type = @@global.allow_document_type;
SELECT @start_allow_document_type;

# Fail to create table with document column with non-innodb engine
--error ER_DOCUMENT_FIELD_IN_NON_INNODB_TABLE
create table t (i int(8), a document, s text(255)) engine=myisam;

# Fail to create table with document column with size specification
--error 1064
create table t (i int(8), a document(65535), s text(255)) engine=innodb;

# Fail to create table with document column with primary key on it
--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create table t (i int(8), a document, s text(255), primary key(a)) engine=innodb;

# Fail to create table with partitioning on a document column
--error ER_FIELD_TYPE_NOT_ALLOWED_AS_PARTITION_FIELD
create table t (i int(8), a document, s text(255))
  partition by range columns(a)
  (partition p0 values less than (0) engine=innodb);

# Fail to create table with partitioning on a non-document column but with non-innodb engine
--error ER_DOCUMENT_FIELD_IN_NON_INNODB_TABLE
create table t (i int(8), a document, s text(255))
  partition by range columns(i)
  (partition p0 values less than (0) engine=myisam);

# Create table with a document column that can be NULL
create table t (i int(8), a document, s text(255), primary key (i)) engine=innodb;
show create table t;

# Fail to create index on a document column
--error ER_DOCUMENT_KEY_NOT_SUPPORTED
alter table t add primary key (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
alter table t add index (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create index doc_idx on t (a);

--error ER_DOCUMENT_KEY_NOT_SUPPORTED
create index doc_idx on t (i, a);

# Fail to partition table on document column
--error ER_DOCUMENT_FIELD_IN_PART_FUNC_ERROR
alter table t partition by hash(a) partitions 8;

# Insert invalid JSON, insertion will succeed, the document filed will be NULL, expecting warnings
insert into t values (1, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", }', 'a1');

# Expecting the number of rows to be 1
SELECT count(*) FROM t;

# Insert invalid values, insertion will succeed, the document filed will be NULL, expecting warnings
insert into t values (2, ' ', 'a2');
insert into t values (3, 123, 'a3');
insert into t values (4, 123.456, 'a4');

# Update with invalid values, it will fail, expecting warnings
update t set a='{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", }' where i = 1;
update t set a=111222333444555666777888999 where i = 2;
update t set a=123456789.123456789;

# Default is NULL
update t set a=DEFAULT;

# Insert JSON document in plain text
insert into t values (5, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", "zipcode":98761 } }', 'a5');
insert into t values (6, '{ "id":102, "name":"Bob", "phone":6507770002, "address":{ "houseNumber":1002, "streetName":"2nd", "zipcode":98762 } }', 'a6');
insert into t values (7, '{ "id":103, "name":"Charlie", "phone":6507770003, "address":{ "houseNumber":1003, "streetName":"3rd", "zipcode":98763, "hoa":39.99 } }', 'a7');
insert into t values (8, '{ "id":104, "name":"David", "phone":6507770004, "address":{ "houseNumber":1004, "streetName":"4th", "zipcode":98764 }, "children":["Alex", "Bob", "Charlie"] }', 'a8');

# Load data from a file
load data infile '../../std_data/type_document_innodb.txt' into table t;

select * from t;
select a from t;

# Temp table with a document type column
# In MySQL 5.6 all temp tables are created by MyISAM engine. But temp tables with document
# type columns still will be handled correctly since they will be treated as blobs.

# Create a table and populate it with some data
create table t1 (a int auto_increment, b varchar(64), c text, d document, primary key (a), key (b, c(128))) engine=innodb;

# Here we end up with 16382 rows in the table
--disable_query_log
insert into t1 (b, c, d) values (repeat('b', 64), repeat('c', 256), '{ "id":201, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "street":"1st", "zipcode":98761 } }');
insert into t1 (b, c, d) values (repeat('B', 64), repeat('C', 256), '{ "id":202, "name":"David", "phone":6507770002, "address":{ "houseNumber":1004, "street":"2nd", "zipcode":98762 }, "children":["Alex", "Bob", "Charlie"] }');
let $i=12;
while ($i) {
  --eval INSERT INTO t1 (b, c, d) VALUES ($i, $i * $i, '{ "id":202, "name":"David", "phone":6507770002, "address":{ "houseNumber":1004, "street":"2nd", "zipcode":98762 }, "children":["Alex", "Bob", "Charlie"] }');
  INSERT INTO t1 (b, c, d) SELECT b, c, d FROM t1 order by a;
  dec $i;
}
--enable_query_log

SELECT * FROM t1 WHERE a >= 1000 and a <= 1010;

--error 1064
SELECT CAST(c as document) FROM t1 WHERE a >= 1000 and a <= 1010;

# Create table with a document column that cannot be NULL
create table t2 (i int(8), a document not null, s text(255), primary key (i)) engine=innodb;
show create table t2;

# Insert invalid JSON, since the document field cannot be NULL so the insertion will fail, expecting errors

--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2 values (1, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", }', 'a1');

--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2 values (2, ' ', 'a2');

--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2 values (3, 123, 'a3');

--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
insert into t2 values (4, 123.456, 'a4');

# Expecting the number of rows to be 0
SELECT count(*) FROM t2;

#Insert valid JSON, trying to update with invalid JSON, expecting warnings
insert into t2 values (1, '{ "id":101, "name":"Alex", "phone":6507770001, "address":{ "houseNumber":1001, "streetName":"1st", "zipcode":98761 } }', 'a5');

# Update with invalid JSON, since the document field cannot be NULL so the update will fail, expecting errors
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
update t2 set a='{ "id":102, "name":"Bob", "phone":6507770002, "address":{ "houseNumber":1002, "streetName":"2nd", }' where i = 1;
# Expecting the row unchanged
SELECT * from t2;

# Default is not defined and the document field cannot be NULL, so it will fail, expecting errors
--error ER_INVALID_VALUE_FOR_DOCUMENT_FIELD
update t2 set a=DEFAULT;

# Create table with a document column that can be NULL
create table t_big (i int(8), a document, s text(255), primary key (i)) engine=innodb;
show create table t_big;

# Insert a document whose FBSON size is a little bit less than 16MB (the max size of document type)
# This insertion will succeed
insert into t_big values (1, concat("{", repeat("\"json-key\":\"json-value\",", 670000), "\"last\":100}"), 'aaa');

# Set sql_mode to strict_trans_tables
set @original_session_sql_mode = @@session.sql_mode;
set @@session.sql_mode = strict_trans_tables;
select @@session.sql_mode;

# Insert a document whose FBSON size is a little bit greater than 16MB (the max size of document type)
# The document column will be set to NULL with warnings, but since sql_mode has been set to strict_trans_tables,
# the warning will be treated as an error and the insertion will fail eventually
--error ER_TOO_BIG_DOCUMENT_FIELDLENGTH
insert into t_big values (2, concat("{", repeat("\"json-key\":\"json-value\",", 700000), "\"last\":100}"), 'bbb');

# Restore the value of sql_mode
set @@session.sql_mode = @original_session_sql_mode;
select @@session.sql_mode;

# Insert a document whose FBSON size is a little bit greater than 16MB (the max size of document type)
# This insertion will succeed but with warnings, the document column will be NULL
insert into t_big values (2, concat("{", repeat("\"json-key\":\"json-value\",", 700000), "\"last\":100}"), 'bbb');

select count(*) from t_big;
select i, s from t_big;

# Create table with a document column that cannot be NULL
create table t_big2 (i int(8), a document not null, s text(255), primary key (i)) engine=innodb;
show create table t_big2;

# Insert a document whose FBSON size is a little bit less than 16MB (the max size of document type)
# This insertion will succeed
insert into t_big2 values (1, concat("{", repeat("\"json-key\":\"json-value\",", 670000), "\"last\":100}"), 'aaa');

# Insert a document whose FBSON size is a little bit greater than 16MB (the max size of document type)
# This insertion will fail
--error ER_TOO_BIG_DOCUMENT_FIELDLENGTH
insert into t_big2 values (2, concat("{", repeat("\"json-key\":\"json-value\",", 700000), "\"last\":100}"), 'bbb');

select count(*) from t_big2;
select i, s from t_big2;

# Disable document type when @@global.allow_document_type is false.
SET @@global.allow_document_type = false;
SELECT @@global.allow_document_type;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
create table t3 (i int(8), a document, s text(255)) engine=innodb;

create table t3 (i int(8), s text(255)) engine=innodb;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
alter table t3 add column a document;

--error ER_DOCUMENT_FIELD_NOT_ALLOWED
alter table t3 modify column s document;

# Enable document type
SET @@global.allow_document_type = true;
SELECT @@global.allow_document_type;

alter table t3 add column a document;

alter table t3 modify column s document;

# Restore the original value
SET @@global.allow_document_type = @start_allow_document_type;
SELECT @@global.allow_document_type;

checksum table t_big;
connection slave;
# Should be same as that on master
checksum table t_big;

connection master;
drop table t, t1, t2, t3, t_big, t_big2;

--source include/rpl_end.inc
