--source include/have_innodb.inc

--disable_warnings
DROP TABLE if exists t1;
--enable_warnings

# Suppress the warning as it is expected that
# dict_stats_process_entry_from_defrag_pool running in the background will
# increase the table's ref count, which causes the warning during dropping
# table t1.
--disable_query_log
call mtr.add_suppression("InnoDB: Warning: MySQL is trying to drop table ");
--enable_query_log

let $page_size = query_get_value(select @@innodb_page_size, @@innodb_page_size, 1);

# Create table.
CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY AUTO_INCREMENT, b VARCHAR(256), KEY SECOND(a, b)) ENGINE=INNODB;

--echo ## Test-1 defragment an empty table
alter table t1 defragment;

--echo ## Test-2 defragment a single page table
INSERT INTO t1 VALUES (1, REPEAT('A', 256));
INSERT INTO t1 VALUES (2, REPEAT('A', 256));
INSERT INTO t1 VALUES (3, REPEAT('A', 256));
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;

alter table t1 defragment;

--echo ## Test-3 defragment (somewhat) in parallel with delete queries

let $delete_size = 120;
delimiter //;
create procedure defragment()
begin
  set @i = 0;
  repeat
    set @i = @i + 1;
    alter table t1 defragment;
    select sleep(0.5);
  until @i = 3 end repeat;
end //
delimiter ;//


# Populate table.
--disable_query_log
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
INSERT INTO t1 (b) SELECT b from t1;
--enable_query_log

select count(*) from t1;

connect (con1,localhost,root,,test,$MASTER_MYPORT,$MASTER_MYSOCK);

connection con1;
--send call defragment()

connection default;

--disable_query_log
let $size = $delete_size;
while ($size)
{
    let $j =  100 * $size;
    eval delete from t1 where a between $j - 20 and $j;
    dec $size;
}
--enable_query_log

connection con1;
--disable_result_log
--reap
--enable_result_log

connection default;
disconnect con1;

alter table t1 defragment;

--source include/restart_mysqld.inc
select count(*) from t1;

# Before defragmentation, there are 12288 records. After deletion, there are 10203 records left.
# A 16K page can hold about 57 records. We fill the page 90% full, so there should be less than
# 205 pages total after defragmentation for 16K pages. For 32K page it should be about half
# the number.

let $expected = 205;
if ($page_size == 32768) {
   let $expected = 103;
}

--let $result = query_get_value(select count(*) as result from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' and access_time > 0, result, 1)

if ($result > $expected) {
  --echo fail, $result > $expected
}

select count(*) from t1 force index (second);

# secondary index is slightly bigger than primary index so the number of pages should be similar.
let $expected = 210;
if ($page_size == 32768) {
   let $expected = 105;
}
--replace_result $expected expected
eval select count(*) < $expected from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' and access_time > 0;

--echo ## Test-4 defragment with larger n_pages

# delete some more records
--disable_query_log
let $size = $delete_size;
while ($size)
{
    let $j = 100 * $size;
    eval delete from t1 where a between $j - 30 and $j - 20;
    dec $size;
}
--enable_query_log

SET @@global.innodb_defragment_n_pages = 3;

# This will not reduce number of pages by a lot
alter table t1 defragment;

--source include/restart_mysqld.inc

select count(*) from t1;

# We didn't create large wholes with the previous deletion, so if innodb_defragment_n_pages = 3, we won't be able to free up many pages.
let $expected = 195;
if ($page_size == 32768) {
   let $expected = 97;
}
--replace_result $expected expected
eval select count(*) > $expected from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' and access_time > 0;

select count(*) from t1 force index (second);

# Same holds for secondary index, not many pages are released.
--replace_result $expected expected
eval select count(*) > $expected from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' and access_time > 0;

SET @@global.innodb_defragment_n_pages = 10;

alter table t1 defragment index PRIMARY;

--source include/restart_mysqld.inc

select count(*) from t1;

# This time we used innodb_defragment_n_pages = 10, so we should be able to free up some pages.
let $expected_new = 185;
if ($page_size == 32768) {
   let $expected_new = 93;
}

--let $result = query_get_value(select count(*) as result from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' and access_time > 0, result, 1)

if ($result >= $expected_new) {
  --echo fail, $result >= $expected_new
  select * from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;
}

select count(*) from t1 force index (second);

# We only defragmented the primary index so secondary index size should not change.
--replace_result $expected expected
eval select count(*) > $expected from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' and access_time > 0;

SET @@global.innodb_defragment_n_pages = 10;

alter table t1 defragment index second;
--source include/restart_mysqld.inc
select count(*) from t1 force index (second);

# After defragmenting secondary index the size should be smaller.
--replace_result $expected_new expected
eval select count(*) < $expected_new from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' and access_time > 0;

--echo ## Test-5 kill a defragment command
let $orig_frequency = `select @@global.innodb_defragment_frequency`;
# Make the defragmentation really slow.
set global innodb_defragment_frequency = 1;
--disable_query_log
let $size = $delete_size;
while ($size)
{
    let $j =  100 * $size;
    eval delete from t1 where a between $j - 40 and $j-30;
    dec $size;
}
--enable_query_log

connect(con1,localhost,root,,);
connection con1;
let $conn_id = `select connection_id()`;
send alter table t1 defragment;

# Ensure defrag from send command has started before proceeding
# further in the test.
connection default;
let $wait_condition=
  select count(*) = 1 from information_schema.processlist
  where info like 'alter%';
--source include/wait_condition.inc

--replace_result $conn_id ID
eval kill query $conn_id;

connection con1;
--error ER_QUERY_INTERRUPTED
reap;

# The connection / thread that got ER_QUERY_INTERRUPTED only set a flag
# in the core of the defrag structures. Removal of the index from those
# structures happens asychronously, and we're sometimes seeing test failures
# from Test-6 below because it hasn't happened yet. Since I'm unable to find
# any status variable to know when the async operation has completed,
# use the nuclear option of restarting the server.
--source include/restart_mysqld.inc
connection default;
--enable_reconnect
--source include/wait_until_connected_again.inc
connection con1;
--enable_reconnect
--source include/wait_until_connected_again.inc

--echo ## Test-6 Defragment when feature enabled but defragmentation is paused
connection default;
set @@global.innodb_defragment_pause = true;
connection con1;
send alter table t1 defragment;

# Ensure defrag from send command has started before proceeding
# further in the test.
connection default;
let $wait_condition=
  select count(*) = 1 from information_schema.processlist
  where info like 'alter%';
--source include/wait_condition.inc
select info from information_schema.processlist where info like 'alter%';

set @@global.innodb_defragment_pause = false;
connection con1;
reap;

connection default;

--echo ## Test-7 Defragment when feature disabled should return error
set @my_innodb_defragment = @@global.innodb_defragment;
set @@global.innodb_defragment = false;
--error ER_FEATURE_DISABLED
alter table t1 defragment index PRIMARY;

#
# clean up
#
disconnect con1;
DROP PROCEDURE defragment;
set @@global.innodb_defragment = @my_innodb_defragment;

DROP TABLE t1;
